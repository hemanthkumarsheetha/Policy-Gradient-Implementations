# Policy Gradient Implementations

These Implementations include the following Algorithms:
1) Vanilla Policy Gradients with Baseline
2) Actor-Critic Policy Gradient
3) Proximal Policy Optimization 

All these Algorithms are trained using gym and mujoco environments like CartPole,FrozenLake,HalfCheetah etc

The following graphs represent the variance of the rewards as the no of episodes increase. **The no of episodes are represented as X-Axis and Rewards are represented as Y-Axis. These Graphs are from the CartPole Environment.**

VPG with Baseline

![alt text](https://github.com/researchofhemanth/Policy-Gradient-Implementations/blob/master/vpg_baseline.png)

Actor Critic

![alt text](https://github.com/researchofhemanth/Policy-Gradient-Implementations/blob/master/actor_critic.png)

Proximal Policy Optimization(PPO)

![alt text](https://github.com/researchofhemanth/Policy-Gradient-Implementations/blob/master/ppo.png)
